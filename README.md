# Что было сделано
Был разработан парсер для сбора данных с сайта "Quotes to Scrape". Парсер извлекает цитаты, авторов и теги, а затем сохраняет эти данные в формате JSON.
# Откуда были получены данные
Данные были получены с сайта https://quotes.toscrape.com/, на котором предоставлены цитаты различных известных личностей.
# Как осуществлялся сбор
Сбор данных осуществлялся с использованием библиотек BeautifulSoup для парсинга HTML и requests для выполнения HTTP-запросов. Процесс включает следующие шаги:
+ Отправка GET-запроса на главную страницу сайта;
+ Извлечение HTML-кода страницы;
+ Парсинг HTML с помощью BeautifulSoup для нахождения нужных элементов (цитат, авторов и тегов);
+ Код для определения конца цикла, ищет кнопку "Next", если не находит, то завершает работу. Также можно было сделать по количеству страниц на сайте (их 10) – но, что если сайт вдруг обновится и страниц уже будет больше?
+ Сохранение собранных данных в формате JSON.
# Почему был выбран тот или иной метод/инструмент, а не другой
BeautifulSoup: Эта библиотека удобна для парсинга HTML и позволяет легко извлекать данные из сложных структур. Она хорошо документирована и широко используется в сообществе Python.<br>
Requests: Эта библиотека проста в использовании для выполнения HTTP-запросов и обработки ответов.<br>
Метод эмуляции браузера в данном случае не требуется.
